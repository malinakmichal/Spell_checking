{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, BertTokenizer, T5Tokenizer, BertForMaskedLM, logging\n",
    "import torch\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloaded dataset\n",
    "\n",
    "Subham Sahu, Yogesh Kumar Vishwakarma, Jeevanlal kori, Jitendra Singh Thakur . Evaluating performance of different grammar checking tools, International Journal of Advanced Trends in Computer Science and Engineering, Vol. 9 No. 2 pp. 2227 – 2233, April 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr. no.</th>\n",
       "      <th>Correct Sentence</th>\n",
       "      <th>Errneous Sentence</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>Error Subtype</th>\n",
       "      <th>Error Description</th>\n",
       "      <th>Grammarly</th>\n",
       "      <th>Ginger</th>\n",
       "      <th>ProWrittingAid</th>\n",
       "      <th>LanguageTools</th>\n",
       "      <th>After thr Deadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The child who has a rash was just diagnosed wi...</td>\n",
       "      <td>The child who has a rash.</td>\n",
       "      <td>Sentence Structure Error</td>\n",
       "      <td>Fragment error</td>\n",
       "      <td>missing verb</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Since the drugs have many side effects, the pa...</td>\n",
       "      <td>Since the drugs have many side effects.</td>\n",
       "      <td>Sentence Structure Error</td>\n",
       "      <td>Fragment error</td>\n",
       "      <td>missing verb</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>After the doctor performed the operation, the ...</td>\n",
       "      <td>The doctor performed the operation the patient...</td>\n",
       "      <td>Sentence Structure Error</td>\n",
       "      <td>Run-on error</td>\n",
       "      <td>missing conjunction</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Although the doctor performed the operation, t...</td>\n",
       "      <td>The doctor performed the operation, the patien...</td>\n",
       "      <td>Sentence Structure Error</td>\n",
       "      <td>Run-on error</td>\n",
       "      <td>wrong comma</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>We have hundreds of pages of reading to do; it...</td>\n",
       "      <td>We have hundreds of pages of reading to do, it...</td>\n",
       "      <td>Sentence Structure Error</td>\n",
       "      <td>Run-on error</td>\n",
       "      <td>wrong comma</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr. no.                                   Correct Sentence  \\\n",
       "0      1.0  The child who has a rash was just diagnosed wi...   \n",
       "1      2.0  Since the drugs have many side effects, the pa...   \n",
       "2      3.0  After the doctor performed the operation, the ...   \n",
       "3      4.0  Although the doctor performed the operation, t...   \n",
       "4      5.0  We have hundreds of pages of reading to do; it...   \n",
       "\n",
       "                                   Errneous Sentence  \\\n",
       "0                          The child who has a rash.   \n",
       "1            Since the drugs have many side effects.   \n",
       "2  The doctor performed the operation the patient...   \n",
       "3  The doctor performed the operation, the patien...   \n",
       "4  We have hundreds of pages of reading to do, it...   \n",
       "\n",
       "                 Error Type   Error Subtype    Error Description Grammarly  \\\n",
       "0  Sentence Structure Error  Fragment error         missing verb       YES   \n",
       "1  Sentence Structure Error  Fragment error         missing verb        NO   \n",
       "2  Sentence Structure Error    Run-on error  missing conjunction        NO   \n",
       "3  Sentence Structure Error    Run-on error          wrong comma        NO   \n",
       "4  Sentence Structure Error    Run-on error          wrong comma        NO   \n",
       "\n",
       "  Ginger ProWrittingAid LanguageTools After thr Deadline  \n",
       "0     NO             NO            NO                 NO  \n",
       "1     NO             NO           YES                 NO  \n",
       "2     NO             NO            NO                 NO  \n",
       "3     NO            YES            NO                 NO  \n",
       "4     NO            YES            NO                 NO  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel(\"GTD.xlsx\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_downloaded = dataset[dataset['Error Type'] == \"Spelling Error\"]\n",
    "dataset_downloaded = dataset_downloaded[[\"Correct Sentence\", \"Errneous Sentence\", \"Error Type\"]]\n",
    "dataset_downloaded = dataset_downloaded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Sentence</th>\n",
       "      <th>Errneous Sentence</th>\n",
       "      <th>Error Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>He often quarrelled with his friends.</td>\n",
       "      <td>He often quarelled with his friends.</td>\n",
       "      <td>Spelling Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>We haven't ever been there.</td>\n",
       "      <td>We haven't ever beeen there.</td>\n",
       "      <td>Spelling Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>It was impossible to know his father's name.</td>\n",
       "      <td>It was impossibble to know his father's name.</td>\n",
       "      <td>Spelling Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>The two of us work late hours.</td>\n",
       "      <td>The two of us work lete hours.</td>\n",
       "      <td>Spelling Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>It was drizzling.</td>\n",
       "      <td>It was drizling.</td>\n",
       "      <td>Spelling Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Correct Sentence  \\\n",
       "200         He often quarrelled with his friends.   \n",
       "201                   We haven't ever been there.   \n",
       "202  It was impossible to know his father's name.   \n",
       "203               The two of us work late hours.    \n",
       "204                             It was drizzling.   \n",
       "\n",
       "                                 Errneous Sentence      Error Type  \n",
       "200           He often quarelled with his friends.  Spelling Error  \n",
       "201                   We haven't ever beeen there.  Spelling Error  \n",
       "202  It was impossibble to know his father's name.  Spelling Error  \n",
       "203                The two of us work lete hours.   Spelling Error  \n",
       "204                               It was drizling.  Spelling Error  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_downloaded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_misspelled = [\n",
    "    (\"I hav a dreem to chase.\", \"I have a dream to chase.\"),\n",
    "    (\"She is a grea friend.\", \"She is a great friend.\"),\n",
    "    (\"It was an amazng experience.\", \"It was an amazing experience.\"),\n",
    "    (\"The weather is quite lovly today.\", \"The weather is quite lovely today.\"),\n",
    "    (\"He is definitly coming to the party.\", \"He is definitely coming to the party.\"),\n",
    "    (\"We should go to the beech this weekend.\", \"We should go to the beach this weekend.\"),\n",
    "    (\"This is a beautful painting.\", \"This is a beautiful painting.\"),\n",
    "    (\"Can you beleive it's already October.\", \"Can you believe it's already October.\"),\n",
    "    (\"I need to fix the leaky fauce.\", \"I need to fix the leaky faucet.\"),\n",
    "    (\"The quick brown fox jumps over the lazzy dog.\", \"The quick brown fox jumps over the lazy dog.\"),\n",
    "    (\"She enjoys readng books in her free time.\", \"She enjoys reading books in her free time.\"),\n",
    "    (\"My favorite fruits are bananas and appless.\", \"My favorite fruits are bananas and apples.\"),\n",
    "    (\"I like to drink coffe every morning.\", \"I like to drink coffee every morning.\"),\n",
    "    (\"He is a talented writter.\", \"He is a talented writer.\"),\n",
    "    (\"The flowers are blooming in the gardn.\", \"The flowers are blooming in the garden.\"),\n",
    "    (\"I always forget my umbrella in the rainny season.\", \"I always forget my umbrella in the rainy season.\"),\n",
    "    (\"They went to the restraunt for dinner.\", \"They went to the restaurant for dinner.\"),\n",
    "    (\"Her birthday is on the 25th of Decmber.\", \"Her birthday is on the 25th of December.\"),\n",
    "    (\"This cake is delicius.\", \"This cake is delicious.\"),\n",
    "    (\"I will send you the infromation.\", \"I will send you the information.\"),\n",
    "    (\"He has a great sense of humr.\", \"He has a great sense of humor.\")\n",
    "]\n",
    "\n",
    "\n",
    "dataset_mine = pd.DataFrame(dataset_misspelled, columns=[\"Errneous Sentence\", \"Correct Sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspellchecker library\n",
    "\n",
    "PySpellChecker is a Python library that uses the Levenshtein Distance algorithm to identify and suggest the most suitable replacement for incorrectly spelled words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "def pySpellChecker(dataset):\n",
    "    spell = SpellChecker()\n",
    "    sum = 0\n",
    "    rouge1 = []\n",
    "    data_len = dataset.shape[0]\n",
    "    for row in dataset.iterrows():\n",
    "        text_split = row[1]['Errneous Sentence'].split()\n",
    "        result = []\n",
    "        for word in text_split:\n",
    "            # Checks if word is spelled correctly and replaces it by a correct word\n",
    "            result += [word if not spell.unknown([word]) else (spell.correction(word) if spell.correction(word) else word)]\n",
    "\n",
    "        res_len = len(result)\n",
    "        if res_len > 1:\n",
    "            result[0] = result[0].capitalize()\n",
    "        result = ' '.join(result)\n",
    "        if res_len > 1 and result[-1] != \".\":\n",
    "            result += \".\"\n",
    "\n",
    "        if result == row[1]['Correct Sentence']:\n",
    "            sum += 1\n",
    "\n",
    "        # Calculates ROUGE-1 score\n",
    "        score = scorer.score(row[1]['Correct Sentence'], result)\n",
    "        rouge1.append(score['rouge1'])\n",
    "\n",
    "    f1 = np.mean([s.fmeasure for s in rouge1])\n",
    "    print(\"Rouge F1 score: \", str(round(f1, 2)*100) + \" %\")\n",
    "\n",
    "    print(\"Sentence accuracy: \" + str(round(sum*100/data_len, 2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on my own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge F1 score:  96.0 %\n",
      "Sentence accuracy: 76.19 %\n"
     ]
    }
   ],
   "source": [
    "pySpellChecker(dataset_mine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge F1 score:  96.0 %\n",
      "Sentence accuracy: 53.0 %\n"
     ]
    }
   ],
   "source": [
    "pySpellChecker(dataset_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pros:\n",
    "- Does not generate nonsensical words.\n",
    "- Always ensures correct spelling.\n",
    "\n",
    "### Cons:\n",
    "- Ignores the sentence’s context, relying solely on the closest word by Levenshtein distance.\n",
    "- Works well for individual word corrections but may struggle with contextual nuances.\n",
    "- Although multiple candidate words are often available, the best one is not always selected.\n",
    "\n",
    "\n",
    "### Examples of wrong prediction:\n",
    "\n",
    "- sentence to check: It was drizling.\n",
    "    - prediction: drizling -> drilling\n",
    "    - label: drizling -> drizzling\n",
    "- sentence to check: He is a talented writter.\n",
    "    - prediction: writter -> written\n",
    "    - label: writter -> writer\n",
    "\n",
    "These examples show that even though the spelling is corrected, the resulting sentences may not make sense due to incorrect word choices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM\n",
    "\n",
    "I am using an LLM (T5) fine-tuned for a grammar correction task from Hugging Face. T5-base is an encoder-decoder model developed by Google, designed for text-to-text generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"vennify/t5-base-grammar-correction\"\n",
    "\n",
    "tokenizer_T5 = T5Tokenizer.from_pretrained(checkpoint)\n",
    "model_TP = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "def LLM_spell_checker(dataset):\n",
    "    sum = 0\n",
    "    data_len = dataset.shape[0]\n",
    "    rouge1 = []\n",
    "    for row in dataset.iterrows():\n",
    "        # Tokenizes the sentence that is than sent to the model\n",
    "        input_ids = tokenizer_T5(row[1]['Errneous Sentence'], return_tensors=\"pt\").input_ids\n",
    "        size = len(input_ids[0])\n",
    "\n",
    "        # Generates correct sentence based on the input\n",
    "        output = model_TP.generate(input_ids=input_ids, max_new_tokens=size*1.2)\n",
    "        result = tokenizer_T5.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        if result == row[1]['Correct Sentence']:\n",
    "            sum += 1\n",
    "\n",
    "        score = scorer.score(row[1]['Correct Sentence'], result)\n",
    "        rouge1.append(score['rouge1'])\n",
    "\n",
    "    f1 = np.mean([s.fmeasure for s in rouge1])\n",
    "    print(\"Rouge F1 score: \", str(round(f1, 2)*100) + \" %\")\n",
    "\n",
    "    print(\"Sentence accuracy: \" + str(round(sum*100/data_len, 2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on my own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge F1 score:  97.0 %\n",
      "Sentence accuracy: 76.19 %\n"
     ]
    }
   ],
   "source": [
    "LLM_spell_checker(dataset_mine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge F1 score:  94.0 %\n",
      "Sentence accuracy: 43.0 %\n"
     ]
    }
   ],
   "source": [
    "LLM_spell_checker(dataset_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros:\n",
    "- Evaluates the context of the sentence to select the most appropriate word.\n",
    "\n",
    "#### Cons:\n",
    "- Occasionally substitutes words that fit the sentence better but do not match the intended correction, which can be problematic when only spelling accuracy is desired.\n",
    "\n",
    "\n",
    "#### Examples of wrong prediction:\n",
    "\n",
    "- sentence to check: She is a grea friend.\n",
    "    - prediction: grea -> good\n",
    "    - label: grea -> great\n",
    "- sentence to check: The quick brown fox jumps over the lazzy dog.\n",
    "    - prediction: lazzy -> lazzy\n",
    "    - label: lazzy -> lazy\n",
    "\n",
    "These examples highlight two key issues:\n",
    "- The model sometimes fails to correct spelling mistakes.\n",
    "- In other cases, it replaces misspelled words with synonyms, maintaining the meaning but diverging from the desired correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of LLM and pyspellchecker\n",
    "\n",
    "I also experimented with combining both approaches to achieve better results. Specifically, I used PySpellChecker to identify misspelled words and generate candidate corrections. I then replaced the misspelled word with a [MASK] token and used a BERT language model to predict the best-fitting word from the set of candidates. The word with the highest score was selected as the final correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_BERT = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_BERT = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def Combination_spell_checker(dataset):\n",
    "    sum = 0\n",
    "    data_len = dataset.shape[0]\n",
    "    rouge1 = []\n",
    "    for row in dataset.iterrows():\n",
    "        sentence = row[1]['Errneous Sentence']\n",
    "        if len(sentence) > 1 and sentence[-1] in [\".\", \"?\", \"!\"]:\n",
    "            sentence = sentence[:-1]\n",
    "        text_split = sentence.split()\n",
    "        \n",
    "        result = []\n",
    "        spell = SpellChecker()\n",
    "\n",
    "        # For each word in the sentance checks the spelling using PySpellChecker and if it wrong uses BERT model to predict the correct replacement\n",
    "        for index, word in enumerate(text_split):\n",
    "            if not spell.unknown([word]):\n",
    "                # Word is spelled correctly and can be appended to result\n",
    "                result += [word]\n",
    "            else:\n",
    "                # Word is spelled incorrectly and similar words (Levensthein distance) are used in BERT model\n",
    "                if spell.correction(word):\n",
    "                    candidates = list(spell.candidates(word))\n",
    "                    text_split_mask = list(text_split)\n",
    "\n",
    "                    # Incorrectly spelled word is masked\n",
    "                    text_split_mask[index] = \"[MASK]\"\n",
    "                    sentence_mask = \" \".join(text_split_mask)\n",
    "                    input_ids = tokenizer_BERT(sentence_mask, return_tensors=\"pt\").input_ids\n",
    "                    mask_index = (input_ids == tokenizer_BERT.mask_token_id).nonzero(as_tuple=True)[1].item()\n",
    "                \n",
    "                    # Tokenization of candidates words\n",
    "                    candidate_ids = [tokenizer_BERT(word, add_special_tokens=False).input_ids[0] for word in candidates]\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model_BERT(input_ids)\n",
    "                        logits = outputs.logits[0, mask_index]\n",
    "\n",
    "                    # Only predictions of the candidate words are used\n",
    "                    candidate_scores = {word: logits[token_id].item() for word, token_id in zip(candidates, candidate_ids)}\n",
    "\n",
    "                    # The canditate word with highest score is appended to result\n",
    "                    best_word = max(candidate_scores, key=candidate_scores.get) \n",
    "                    result += [best_word]\n",
    "                else:\n",
    "                    # PySpellChecker did not provide any replacements\n",
    "                    result += [word]\n",
    "\n",
    "        res_len = len(result)\n",
    "        if res_len > 1:\n",
    "            result[0] = result[0].capitalize()\n",
    "        result = ' '.join(result)\n",
    "        if res_len > 1 and result[-1] != \".\":\n",
    "            result += \".\"\n",
    "\n",
    "        if result == row[1]['Correct Sentence']:\n",
    "            sum += 1\n",
    "\n",
    "        score = scorer.score(row[1]['Correct Sentence'], result)\n",
    "        rouge1.append(score['rouge1'])\n",
    "\n",
    "    f1 = np.mean([s.fmeasure for s in rouge1])\n",
    "    print(\"Rouge F1 score: \", str(round(f1, 2)*100) + \" %\")\n",
    "\n",
    "    print(\"Sentence accuracy: \" + str(round(sum*100/data_len, 2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on my own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge F1 score:  97.0 %\n",
      "Sentence accuracy: 80.95 %\n"
     ]
    }
   ],
   "source": [
    "Combination_spell_checker(dataset_mine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge F1 score:  97.0 %\n",
      "Sentence accuracy: 57.0 %\n"
     ]
    }
   ],
   "source": [
    "Combination_spell_checker(dataset_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is marginally better than the previous two methods, but the improvement is minor.\n",
    "#### Pros:\n",
    "- The model understands context and modifies only misspelled words.\n",
    "#### Cons:\n",
    "- This model may have longer inference times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
